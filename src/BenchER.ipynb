{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d7c838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, ks_2samp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import *\n",
    "import itertools\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import brown\n",
    "from random import sample\n",
    "try:\n",
    "    nltk.download('universal_tagset')\n",
    "except Exception:\n",
    "    pass\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.schema import CreateSchema, DropSchema\n",
    "import graphviz\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d8d76a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "tables_number = 50\n",
    "repeated_coeff = 0.1\n",
    "round_coeff = 1\n",
    "schema_number = 5\n",
    "hypothesis_coeff = 1.00\n",
    "columns_min = 2\n",
    "columns_max = 5\n",
    "array_amount = 1000\n",
    "mixed_distibutions_amount = 3\n",
    "low = 0.2\n",
    "\n",
    "distibutions_type = \"one\"  # [\"one\", \"mixed\"]\n",
    "\n",
    "db_name = 'postgres'\n",
    "schemas_all = []\n",
    "\n",
    "function_words = ['data', 'index', 'columns', 'copy', 'where', 'first']\n",
    "frequency_list = FreqDist(i.lower() for i in brown.words())\n",
    "data_c = sample([i for i, j in frequency_list.items() if j >= 1 and len(i) >= 1 and i.find('`')==-1 and i.find(\"'\")==-1 and i not in function_words], int(tables_number * columns_max))\n",
    "data_t = sample([i for i, j in frequency_list.items() if j >= 10 and len(i) >= 3 and i.find('`')==-1 and i.find(\"'\")==-1 and i not in function_words and i not in data_c], tables_number)\n",
    "data_s = sample([i for i, j in frequency_list.items() if j >= 100 and len(i) >= 5 and i.find('`')==-1 and i.find(\"'\")==-1 and i not in function_words and i not in data_c and i not in data_t], schema_number)\n",
    "\n",
    "all_dist = [getattr(stats, d) for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_continuous)]\n",
    "distsributions = [x.name for x in all_dist]\n",
    "distributions_processed = []\n",
    "\n",
    "for j in distsributions:\n",
    "    try:\n",
    "        getattr(scipy.stats, j).rvs(size=1)\n",
    "        distributions_processed.append(j)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# distributions = distributions_processed\n",
    "distributions = ['norm', 'uniform', 'logistic', 'halfnorm', 'expon']\n",
    "\n",
    "d = random.choices(distributions, k = int(len(data_c) - (len(data_c) * repeated_coeff)))\n",
    "\n",
    "class DistributionsMixed(scipy.stats.rv_continuous):\n",
    "    def __init__(self, submodels, *args, weights = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.submodels = submodels\n",
    "        self.weights = [w / sum(weights) for w in weights]\n",
    "        \n",
    "    def _pdf(self, x):\n",
    "        pdf = self.submodels[0].pdf(x) * self.weights[0]\n",
    "        for submodel, weight in zip(self.submodels[1:], self.weights[1:]):\n",
    "            pdf += submodel.pdf(x)  * weight\n",
    "        return pdf        \n",
    "\n",
    "    def rvs(self, size):\n",
    "        submodel_choices = np.random.choice(len(self.submodels), size=size, p = self.weights)\n",
    "        submodel_samples = [submodel.rvs(size=size) for submodel in self.submodels]\n",
    "        rvs = np.choose(submodel_choices, submodel_samples)\n",
    "        return rvs\n",
    "\n",
    "for count, j in enumerate(d):\n",
    "    if distibutions_type == 'one':\n",
    "        data_column = getattr(scipy.stats, j).rvs(loc=random.choice([h for h in range(-5, 5)]), scale=random.choice([h for h in range(1, 2)]), size=array_amount)\n",
    "    elif distibutions_type == 'mixed':\n",
    "        a = np.random.rand(mixed_distibutions_amount)\n",
    "        a = (a/a.sum()*(1-low*mixed_distibutions_amount))\n",
    "        weights = a+low\n",
    "        distibutions_mixed = random.sample(distributions, mixed_distibutions_amount)\n",
    "        for d in distibutions_mixed:\n",
    "            mixture_model = DistributionsMixed([getattr(stats, j)(random.choice([h for h in range(-5, 5)]), random.choice([h for h in range(1, 2)])) for j in distibutions_mixed], weights = weights)\n",
    "            array = mixture_model.rvs(array_amount)\n",
    "            #plt.hist(array, bins = 50, density = True)\n",
    "            #plt.show()\n",
    "        data_column = array\n",
    "    #print(count, f\"{j}_{count}\")\n",
    "    df.loc[:, f\"{j}_{count}\"] = np.array(np.round(data_column, round_coeff)).tolist()\n",
    "    #plt.hist(data_column, bins = 50, density = True, label = 'Distribution')\n",
    "    #plt.show()\n",
    "    \n",
    "for i in range(int(len(data_c) * repeated_coeff)):\n",
    "    random_column = sample(list(df.columns), 1)[0]\n",
    "    df[df.shape[1]] = df[random_column].copy()\n",
    "\n",
    "for col, col2 in zip(df.columns, data_c):\n",
    "    df.rename({col: col2}, axis=1, inplace=True)\n",
    "    \n",
    "correlations = {}\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "for col_a, col_b in itertools.combinations(columns, 2):\n",
    "    correlations[col_a + '->' + col_b] = stats.ks_2samp(df.loc[:, col_a], df.loc[:, col_b], method='exact', alternative='two-sided')\n",
    "\n",
    "result = DataFrame.from_dict(correlations, orient='index')\n",
    "result.columns = ['statistics', 'p_value']\n",
    "result = result[result.p_value >= hypothesis_coeff]\n",
    "\n",
    "connectable = create_engine(\"postgresql+psycopg2://postgres:1@localhost:5432/postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ec58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_s:\n",
    "    with connectable.connect() as connection:\n",
    "\n",
    "        schemas = list(connection.execute(text(f\"SELECT * FROM information_schema.schemata where catalog_name = '{db_name}' and schema_name not like '%pg_%' and schema_name != 'information_schema'\")).fetchall())\n",
    "\n",
    "        for i in schemas:\n",
    "            for j in i:\n",
    "                if j not in schemas_all:\n",
    "                    schemas_all.append(j)\n",
    "\n",
    "with connectable.connect() as connection:\n",
    "    for s in schemas_all:\n",
    "        try:\n",
    "            connection.execute(DropSchema(s, cascade=True, if_exists=True))\n",
    "            connection.commit()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "tables_per_schema = {}\n",
    "        \n",
    "for i in data_s:\n",
    "    if i not in tables_per_schema:\n",
    "        tables_per_schema[i] = []\n",
    "    with connectable.connect() as connection:\n",
    "        connection.execute(CreateSchema(i, if_not_exists=True))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3231469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tables_number):\n",
    "    with connectable.connect() as connection:\n",
    "        schema_index = str(random.choice([i for i in data_s]))\n",
    "        table_name = str(random.choice([i for i in data_t]))\n",
    "        distribution_indexes = list(random.choices(data_c, k = random.randint(columns_min, columns_max)))\n",
    "        try:\n",
    "            for d in distribution_indexes:\n",
    "                tables_per_schema[schema_index].append(d)\n",
    "                data_c.remove(d)\n",
    "            df[tables_per_schema[schema_index]].to_sql(table_name, connection, schema=schema_index, if_exists='fail', index=False)\n",
    "            data_t.remove(table_name)\n",
    "            connection.commit()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6855324c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BenchER - Benchmark for ER-models.gv.svg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = graphviz.Digraph('BenchER - Benchmark for ER-models', comment='Author: Moskalev Dmitry', format='svg')  \n",
    "tables_per_schema = {k: v for k, v in tables_per_schema.items() if len(v) != 0}\n",
    "\n",
    "for i in result.index:\n",
    "    col1 = str(i.split('->')[0])\n",
    "    col2 = str(i.split('->')[1])\n",
    "    try:\n",
    "        for key, value in tables_per_schema.items():\n",
    "            if col1 in value:\n",
    "                schema1 = key\n",
    "        if col2 in value:\n",
    "                schema2 = key\n",
    "    \n",
    "        if result.loc[i].p_value >= hypothesis_coeff:\n",
    "            #print(schema1 + '.' + col1 + ';' + schema2 + '.' + col2)  # GT\n",
    "            dot.edge(schema1+ '.' + col1, schema2 + '.' + col2, label=f'{round(result.loc[i].p_value, 2)}')\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "dot.view()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Moskalev Dmitry"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "title": "BenchER"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
